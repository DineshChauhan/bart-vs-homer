{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bart vs. Homer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import platform\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "import skimage\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, MaxPooling2D,\n",
    "                                    GlobalAveragePooling2D, Activation)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, InputLayer\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 2.7.15rc1\n",
      "Matplotlib version: 2.2.3\n",
      "SKImage version: 0.14.1\n",
      "SKLearn version: 0.20.0\n",
      "Numpy version: 1.15.2\n",
      "Tensorflow version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "print \"Python version:\", platform.python_version()\n",
    "print \"Matplotlib version:\", matplotlib.__version__\n",
    "print \"SKImage version:\", skimage.__version__\n",
    "print \"SKLearn version:\", sklearn.__version__\n",
    "print \"Numpy version:\", np.__version__\n",
    "print \"Tensorflow version:\", tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2character = dict(enumerate([\"Bart\", \"Homer\", \"Background\"]))\n",
    "character2label = {character: label for label, character in label2character.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_labels(directory, shuffle=True):\n",
    "    gen = image.ImageDataGenerator()\n",
    "    batches = gen.flow_from_directory(directory, target_size=(360, 640), batch_size=1, shuffle=shuffle)\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    for i in range(batches.n):\n",
    "        img, label = batches.next()\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    data = np.concatenate(imgs)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_and_heatmap(images, heatmaps, predictions, number):\n",
    "    pred_bart, pred_homer = predictions[number]\n",
    "    label = np.argmax(predictions[number])\n",
    "    print \"Predicted label:\", label2character[label]\n",
    "    print \"Bart confidence:\", round(pred_bart * 100, 2), \"% - Homer confidence:\", round(pred_homer * 100, 2), \"%\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    img = images[number].astype(np.uint8)\n",
    "\n",
    "    for character in (\"Bart\", \"Homer\"):\n",
    "        label = character2label[character]\n",
    "        fig.add_subplot(2, 1, label + 1, title=\"Heatmap for \" + character + \" recognition\")\n",
    "        heat_map_low_res = np.moveaxis(heatmaps[number], 2, 0)[label]\n",
    "        heat_map = skimage.transform.resize(heat_map_low_res, (360, 640), mode=\"reflect\", anti_aliasing=True)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(heat_map, cmap=\"seismic\", alpha=0.5, vmax=heatmaps[number].max())\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_and_heatmap_with_background(images, heatmaps, predictions, number):\n",
    "    pred_bart, pred_homer, pred_background = predictions[number]\n",
    "    label = np.argmax(predictions[number])\n",
    "    print \"Predicted label:\", label2character[label]\n",
    "    print \"Bart confidence:\", round(pred_bart * 100, 2), \"% - Homer confidence:\", round(pred_homer * 100, 2), \"% - Background confidence:\", round(pred_background * 100, 2), \"%\" \n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    img = images[number].astype(np.uint8)\n",
    "\n",
    "    for character in (\"Bart\", \"Homer\", \"Background\"):\n",
    "        label = character2label[character]\n",
    "        fig.add_subplot(3, 1, label + 1, title=\"Heatmap for \" + character + \" recognition\")\n",
    "        heat_map_low_res = np.moveaxis(heatmaps[number], 2, 0)[label]\n",
    "        heat_map = skimage.transform.resize(heat_map_low_res, (360, 640), mode=\"reflect\", anti_aliasing=True)\n",
    "        plt.imshow(img)\n",
    "        plt.imshow(heat_map, cmap=\"seismic\", alpha=0.5, vmax=heatmaps[number].max())\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_fit(training_directory, validation_directory, nb_classes, nb_epochs,\n",
    "                         with_background=False, record_input_global_average_pooling=False):\n",
    "    train_data, train_labels = get_data_and_labels(training_directory)\n",
    "    val_data, val_labels = get_data_and_labels(validation_directory, False)\n",
    "    \n",
    "    vgg16_bottom = VGG16(include_top=False, input_shape=(360, 640, 3), weights='imagenet')\n",
    "    model_bottom = Sequential(VGG16(include_top=False, input_shape=(360, 640, 3), weights='imagenet').layers[:-1])\n",
    "    \n",
    "    print \"Predict output of non trainable layers: Training set\"\n",
    "    post_model_bottom_train_features = model_bottom.predict(train_data, batch_size=1, verbose=1)\n",
    "    \n",
    "    print \"Predict output of non trainable layers: Validation set\"\n",
    "    post_model_bottom_val_features = model_bottom.predict(val_data, batch_size=1, verbose=1)\n",
    "    \n",
    "    model_top = Sequential([\n",
    "                Conv2D(nb_classes, (3, 3), activation='relu', padding='same', name=\"conv_last\"),\n",
    "                GlobalAveragePooling2D(name=\"global_average_pooling\"),\n",
    "                Activation(\"softmax\", name=\"softmax\")\n",
    "            ])\n",
    "    \n",
    "    model_top.compile(loss=categorical_crossentropy, optimizer=Adam(1e-3), metrics=[categorical_accuracy])\n",
    "\n",
    "    print \"Fit the last convolutional layer\"\n",
    "    if not with_background:\n",
    "        model_top.fit(post_model_bottom_train_features, train_labels,\n",
    "                      validation_data=(post_model_bottom_val_features, val_labels),\n",
    "                      epochs=nb_epochs, verbose=0, callbacks=[PlotLossesKeras()], batch_size=1)\n",
    "    else:\n",
    "        model_top.fit(post_model_bottom_train_features, train_labels,\n",
    "                      validation_data=(post_model_bottom_val_features, val_labels),\n",
    "                      epochs=nb_epochs, verbose=0, callbacks=[PlotLossesKeras()], batch_size=1,\n",
    "                      class_weight = {0: 1, 1: 1, 2: 15})        \n",
    "    \n",
    "    inp = x = Input(shape=(360, 640, 3))\n",
    "\n",
    "    for layer in model_bottom.layers + model_top.layers:\n",
    "        if layer.name == 'global_average_pooling':\n",
    "            conv_last = x\n",
    "        x = layer(x)\n",
    "    \n",
    "    model = Model([inp], [x, conv_last])    \n",
    "    \n",
    "    return model, train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train In Front Of House\n",
    "\n",
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_data, val_data = create_model_and_fit(\"InFrontOfHouse/Train\", \"InFrontOfHouse/Valid\", 2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels and last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions, val_last_conv = model.predict(val_data, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels and last convolutional layer on an other background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_front_of_nuclear_data, _ = get_data_and_labels(\"InFrontOfNuclear\")\n",
    "in_front_of_nuclear_predictions, in_front_of_nuclear_last_conv = model.predict(in_front_of_nuclear_data, verbose=1, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display data on an other background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(in_front_of_nuclear_data, in_front_of_nuclear_last_conv, in_front_of_nuclear_predictions, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train In Front Of Several backgrounds\n",
    "\n",
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_data, val_data = create_model_and_fit(\"SeveralBackgrounds/Train\", \"SeveralBackgrounds/Valid\", 2, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels and last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions, val_last_conv = model.predict(val_data, verbose=1, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(val_data, val_last_conv, val_predictions, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels and last convolutional layer on inverted backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_backgrounds_data, _ = get_data_and_labels(\"InvertedBackgrounds\")\n",
    "inverted_backgrounds_predictions, inverted_backgrounds_last_conv = model.predict(inverted_backgrounds_data, verbose=1, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display data on an inverted backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(inverted_backgrounds_data, inverted_backgrounds_last_conv, inverted_backgrounds_predictions, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels and last convolutional layer for background only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_only_data, _ = get_data_and_labels(\"BackgroundOnly\")\n",
    "background_only_predictions, background_only_last_conv = model.predict(background_only_data, verbose=1, batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display data for background only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(background_only_data, background_only_last_conv, background_only_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap(background_only_data, background_only_last_conv, background_only_predictions, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train With Backgrounds as Class\n",
    "\n",
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_data, val_data = create_model_and_fit(\"WithBackgroundsAsClass/Train\", \"WithBackgroundsAsClass/Valid\", 3,  40, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict labels and last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions, val_last_conv = model.predict(val_data, verbose=1, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image_and_heatmap_with_background(val_data, val_last_conv, val_predictions, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
